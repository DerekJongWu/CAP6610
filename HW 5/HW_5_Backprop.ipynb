{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "[ 0. -1.] [[0.6688637]]\n",
      "[0. 1.] [[0.47895352]]\n",
      "[1. 0.] [[0.50432069]]\n",
      "[-1.  0.] [[0.5088423]]\n",
      "[ 0.42496802 -2.64762792] [[0.50441164]]\n",
      "[-0.10131054  1.176939  ] [[0.50224733]]\n",
      "[0.52502783 1.85372154] [[0.53463593]]\n",
      "[0.83927604 1.43925258] [[0.50463182]]\n",
      "[-1.6114795   0.60800971] [[0.50884283]]\n",
      "[-1.88950037  0.70290821] [[0.50884283]]\n",
      "[-0.75801017 -1.11783266] [[0.50877892]]\n",
      "[ 0.98472684 -1.12661064] [[0.5043172]]\n",
      "[-0.56475186 -1.23036054] [[0.50797997]]\n",
      "[-0.36416127  1.11396575] [[0.50857227]]\n",
      "[-0.78470761 -1.06003551] [[0.50880109]]\n",
      "[-1.49370614  0.52102444] [[0.50884283]]\n",
      "[-0.98270337  2.16349001] [[0.50884281]]\n",
      "[-1.01955339 -0.2046262 ] [[0.50884226]]\n",
      "[-1.86673475  0.82402997] [[0.50884283]]\n",
      "[0.56764425 1.25275877] [[0.51140925]]\n",
      "[-1.46417012  0.43819638] [[0.50884283]]\n",
      "[-0.15204204  2.37671899] [[0.50830784]]\n",
      "[1.3648757  0.51059828] [[0.50431639]]\n",
      "[1.10563848 0.71880028] [[0.50431989]]\n",
      "[-1.13919641 -0.74754353] [[0.50884253]]\n",
      "[-2.02123938 -0.76056331] [[0.50884283]]\n",
      "[-0.20262963 -1.28308966] [[0.43070242]]\n",
      "[1.34567602 0.12064244] [[0.50431636]]\n",
      "[2.20791996 0.4240772 ] [[0.50431629]]\n",
      "[ 1.40029095 -0.50464965] [[0.5043163]]\n",
      "[-2.03669019 -0.58625195] [[0.50884283]]\n",
      "[0.67711622 1.59574625] [[0.50739735]]\n",
      "[-1.53200161  0.35854925] [[0.50884283]]\n",
      "[-1.48982256  0.3408225 ] [[0.50884283]]\n",
      "[-1.30663594  0.09337863] [[0.50884282]]\n",
      "[1.2329423  0.29988582] [[0.50431667]]\n",
      "[0.58345987 1.16504812] [[0.50939479]]\n",
      "[ 0.08301202 -2.20419844] [[0.51812651]]\n",
      "[ 1.57791774 -0.98119731] [[0.50431629]]\n",
      "[-0.04649735  1.40986835] [[0.49976698]]\n",
      "[1.33371124 0.8487666 ] [[0.50431654]]\n",
      "[-0.68302514 -2.25565233] [[0.50786612]]\n",
      "[-0.06083796 -2.01921335] [[0.60065243]]\n",
      "[ 1.49180327 -0.39166307] [[0.50431629]]\n",
      "[0.30436759 1.34856643] [[0.67547688]]\n",
      "[-0.61700561  1.61298468] [[0.50883766]]\n",
      "[1.15567697 0.58647899] [[0.50431785]]\n",
      "[ 1.16272164 -0.97130963] [[0.50431641]]\n",
      "[-0.18352765 -1.06646087] [[0.43733069]]\n",
      "[-0.44227112  1.24711121] [[0.5087605]]\n",
      "[0.33361095 1.28080504] [[0.62419274]]\n",
      "[ 2.12544374 -0.47080713] [[0.50431629]]\n",
      "[0.79149867 1.10469698] [[0.50465673]]\n",
      "[-0.40297787 -1.43132458] [[0.49992088]]\n",
      "[-0.12739772 -1.15414897] [[0.3738607]]\n",
      "[2.29941741 0.7954016 ] [[0.50431629]]\n",
      "[0.1714476  1.11832874] [[0.69025156]]\n",
      "[-2.39597688 -0.2634163 ] [[0.50884283]]\n",
      "[-0.17947276 -1.3171248 ] [[0.40486088]]\n",
      "[ 1.264688   -0.78896448] [[0.50431633]]\n",
      "[-0.63942124 -1.73668044] [[0.50809481]]\n",
      "[-1.15705818 -0.74748643] [[0.50884259]]\n",
      "[ 1.18067406 -0.07090064] [[0.5043167]]\n",
      "[-0.8225447  -1.77382587] [[0.50876325]]\n",
      "[-1.26535714  0.05313166] [[0.50884281]]\n",
      "[-1.68223461 -0.7085389 ] [[0.50884283]]\n",
      "[ 0.0858657  -1.77250267] [[0.53019106]]\n",
      "[1.2490462 0.1190831] [[0.50431652]]\n",
      "[-1.67009631  0.39811415] [[0.50884283]]\n",
      "[-2.387367    0.29151496] [[0.50884283]]\n",
      "[0.82823359 2.26065824] [[0.50562704]]\n",
      "[-1.23098494 -0.29783187] [[0.50884278]]\n",
      "[-1.09128016  0.99888192] [[0.50884279]]\n",
      "[1.78169216 0.90463431] [[0.50431629]]\n",
      "[0.49947595 1.69699028] [[0.53692952]]\n",
      "[ 0.79626702 -1.5047105 ] [[0.50432168]]\n",
      "[0.52854611 1.2767216 ] [[0.51629301]]\n",
      "[ 1.45656342 -0.2718136 ] [[0.5043163]]\n",
      "[0.94035308 1.28121939] [[0.50438555]]\n",
      "[-1.23045067 -0.25103477] [[0.50884279]]\n",
      "[-2.29396292  0.93688837] [[0.50884283]]\n",
      "[ 3.67212333 -0.85592298] [[0.50431629]]\n",
      "[-1.71958771 -0.03510175] [[0.50884283]]\n",
      "[-1.31068743 -0.86314561] [[0.50884279]]\n",
      "[-2.59332687  0.84961467] [[0.50884283]]\n",
      "[-1.4886457  -0.41049732] [[0.50884283]]\n",
      "[ 0.89911734 -1.39580302] [[0.50431805]]\n",
      "[-0.57399759 -1.3577128 ] [[0.50790464]]\n",
      "[0.69797725 3.69591672] [[0.56398374]]\n",
      "[-1.24632111 -0.71918387] [[0.50884276]]\n",
      "[-2.3963565  -0.09056706] [[0.50884283]]\n",
      "[ 2.11470475 -0.31077503] [[0.50431629]]\n",
      "[-0.35695416 -1.08745274] [[0.4995776]]\n",
      "[ 0.05415997 -1.29073508] [[0.58083182]]\n",
      "[-0.55803007 -1.00281747] [[0.50818578]]\n",
      "[ 0.74482071 -1.44454612] [[0.50432759]]\n",
      "[0.00233208 1.64884825] [[0.4973694]]\n",
      "[ 0.70403014 -1.51451617] [[0.50433319]]\n",
      "[-0.46604282  1.29251467] [[0.50878595]]\n",
      "[-0.60697074  1.04891056] [[0.50882863]]\n",
      "59\n",
      "[array([[ 0.34532757, -1.25592051,  0.2783287 ],\n",
      "       [-4.18842427, 17.59297303, -4.18301526],\n",
      "       [ 0.52567385, -1.68702469,  0.51882681]]), array([[-0.18527424, -0.19964451,  0.33188273],\n",
      "       [-0.99202021, -0.61332988, -0.39500064],\n",
      "       [-0.05663096, -0.04072934,  0.74470744]]), array([[-1.75637648],\n",
      "       [-0.89398113],\n",
      "       [ 0.91177368]])]\n",
      "[[0.6688637]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-3*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers, activation='sigmoid'):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_prime\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.01, epochs=10500):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            weight_changes = [0]*(len(self.weights))\n",
    "            if k % 10000 == 0: print ('epochs:', k)\n",
    "            for m in range(0,10): \n",
    "                data0 = 0\n",
    "                data1 = 0\n",
    "                balance = True\n",
    "                i = np.random.randint(X.shape[0])\n",
    "                while(balance): \n",
    "                    if y[i] == 0 and data0 == 5: \n",
    "                        i = np.random.randint(X.shape[0])\n",
    "                    elif y[i] == 0 and data1 == 5: \n",
    "                        i = np.random.randint(X.shape[0])\n",
    "                    else: \n",
    "                        balance = False \n",
    "                if y[i] == 0 : \n",
    "                    data0 += 1 \n",
    "                else: \n",
    "                    data1 += 1 \n",
    "                a = [X[i]]\n",
    "     \n",
    "                for l in range(len(self.weights)):\n",
    "                        dot_value = np.dot(a[l], self.weights[l])\n",
    "                        activation = self.activation(dot_value)\n",
    "                        a.append(activation)\n",
    "                # output layer\n",
    "                error = a[-1] - y[i]\n",
    "                deltas = [error]\n",
    "\n",
    "                # we need to begin at the second to last layer \n",
    "                # (a layer before the output layer)\n",
    "                for l in range(len(a) - 2, 0, -1): \n",
    "                    deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "                # reverse\n",
    "                # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "                deltas.reverse()\n",
    "\n",
    "                # backpropagation\n",
    "                # 1. Multiply its output delta and input activation \n",
    "                #    to get the gradient of the weight.\n",
    "                # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "                for i in range(len(self.weights)):\n",
    "                    layer = np.atleast_2d(a[i])\n",
    "                    delta = np.atleast_2d(deltas[i])\n",
    "                    weight_changes[i] -= learning_rate * layer.T.dot(delta)\n",
    "                    \n",
    "            for i in range(len(self.weights)): \n",
    "                self.weights[i] = np.add(self.weights[i],weight_changes[i])\n",
    "                \n",
    "    def predict(self, x): \n",
    "        a = np.concatenate((np.array([[1]]), np.array([x])), axis=1)      \n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,2,1])\n",
    "\n",
    "    X = np.array([[0, -1],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [-1, 0]])\n",
    "\n",
    "    y = np.array([1, 1, 0, 0])\n",
    "    class1 = 2\n",
    "    class2 = 2\n",
    "    while len(X) < 100: \n",
    "        val = np.random.normal(size = 2)\n",
    "        val1 = abs(val[0])\n",
    "        val2 = abs(val[1])\n",
    "        if ((val1 > 1) and (val2 < 1)): \n",
    "            if class1 < 50: \n",
    "                label = 0\n",
    "                y = np.append(y,label)\n",
    "                val = [val]\n",
    "                X = np.append(X,val,axis=0)\n",
    "                class1 +=1\n",
    "            else: continue\n",
    "        if ((val1 < 1) and (val2 > 1)):\n",
    "            if class2 < 50: \n",
    "                label = 1 \n",
    "                y = np.append(y,label)\n",
    "                val = [val]\n",
    "                X = np.append(X,val,axis=0)\n",
    "                class2 +=1\n",
    "            else: continue\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    #print(nn.weights)\n",
    "    index = 0 \n",
    "    misclassified = 0\n",
    "    wrong = 0 \n",
    "    for e in X:\n",
    "        out = nn.predict(e)\n",
    "        comp = y[index]\n",
    "        print(e, out)\n",
    "        if abs(out-comp) >= 0.5: \n",
    "            misclassified += 1\n",
    "            index += 1\n",
    "        else:\n",
    "            index += 1\n",
    "            continue\n",
    "    ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "    x = np.concatenate((ones.T, X), axis=1)\n",
    "    print(misclassified)\n",
    "    print(nn.weights)\n",
    "    \n",
    "    x_axis1 = []\n",
    "    y_axis1 = []\n",
    "    x_axis0 = []\n",
    "    y_axis0 = []\n",
    "    layer1 = (np.matmul(x,nn.weights[0]))\n",
    "    layer2 = (np.matmul(layer1,nn.weights[1]))\n",
    "    print(nn.predict(X[0]))\n",
    "    for i in range (0,99): \n",
    "        if y[i] == 0: \n",
    "            x_axis0.append(layer2[i][0])\n",
    "            y_axis0.append(layer2[i][1])\n",
    "            #x_axis0.append(nn.predict(X[i])[0])\n",
    "            #y_axis0.append(0)\n",
    "        if y[i] == 1: \n",
    "            x_axis1.append(layer1[i][0])\n",
    "            y_axis1.append(layer1[i][1])\n",
    "            #if (nn.predict(X[i])[0]) <0.5: \n",
    "                #continue\n",
    "           #else: \n",
    "                #x_axis1.append(nn.predict(X[i])[0])\n",
    "                #y_axis1.append(0)\n",
    "    plt.figure()\n",
    "    plt.scatter(x_axis0,y_axis0, color = 'r')\n",
    "    plt.scatter(x_axis1,y_axis1, color = 'b')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
